{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f68a55-4852-4216-b86a-800fd63f78a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver.find_element(By.?) ? can be CSS_SELECTOR,ID etc\n",
    "#driver.find_elements(By.?) to find multiple elements with the selector or ids. we will get array of elements.\n",
    "#element.text.strip() to get text of element. \n",
    "#element.get_attribute('href') to get the url in the element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c325acd1-5445-4627-93ff-25ac4746137f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.tandfonline.com/toc/tjis20/3/4?nav=tocList\n",
      "Error while finding issues for https://www.tandfonline.com/toc/tjis20/3/4?nav=tocList: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF747B238A5+3004357]\n",
      "\t(No symbol) [0x00007FF7477B9970]\n",
      "\t(No symbol) [0x00007FF74766582A]\n",
      "\t(No symbol) [0x00007FF7476B5B8E]\n",
      "\t(No symbol) [0x00007FF7476B5E7C]\n",
      "\t(No symbol) [0x00007FF7476FEC27]\n",
      "\t(No symbol) [0x00007FF7476DBC1F]\n",
      "\t(No symbol) [0x00007FF7476FBA4C]\n",
      "\t(No symbol) [0x00007FF7476DB983]\n",
      "\t(No symbol) [0x00007FF7476A7628]\n",
      "\t(No symbol) [0x00007FF7476A8791]\n",
      "\tGetHandleVerifier [0x00007FF747B4A00D+3161901]\n",
      "\tGetHandleVerifier [0x00007FF747B9E060+3506048]\n",
      "\tGetHandleVerifier [0x00007FF747B9400D+3465005]\n",
      "\tGetHandleVerifier [0x00007FF747910EEB+830987]\n",
      "\t(No symbol) [0x00007FF7477C467F]\n",
      "\t(No symbol) [0x00007FF7477C09D4]\n",
      "\t(No symbol) [0x00007FF7477C0B6D]\n",
      "\t(No symbol) [0x00007FF7477B0149]\n",
      "\tBaseThreadInitThunk [0x00007FFDE9767344+20]\n",
      "\tRtlUserThreadStart [0x00007FFDE9AC26B1+33]\n",
      "\n",
      "error at article url Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF747B238A5+3004357]\n",
      "\t(No symbol) [0x00007FF7477B9970]\n",
      "\t(No symbol) [0x00007FF74766582A]\n",
      "\t(No symbol) [0x00007FF7476B5B8E]\n",
      "\t(No symbol) [0x00007FF7476B5E7C]\n",
      "\t(No symbol) [0x00007FF7476A93DC]\n",
      "\t(No symbol) [0x00007FF7476DBC1F]\n",
      "\t(No symbol) [0x00007FF7476A92A6]\n",
      "\t(No symbol) [0x00007FF7476DBDF0]\n",
      "\t(No symbol) [0x00007FF7476FBA4C]\n",
      "\t(No symbol) [0x00007FF7476DB983]\n",
      "\t(No symbol) [0x00007FF7476A7628]\n",
      "\t(No symbol) [0x00007FF7476A8791]\n",
      "\tGetHandleVerifier [0x00007FF747B4A00D+3161901]\n",
      "\tGetHandleVerifier [0x00007FF747B9E060+3506048]\n",
      "\tGetHandleVerifier [0x00007FF747B9400D+3465005]\n",
      "\tGetHandleVerifier [0x00007FF747910EEB+830987]\n",
      "\t(No symbol) [0x00007FF7477C467F]\n",
      "\t(No symbol) [0x00007FF7477C09D4]\n",
      "\t(No symbol) [0x00007FF7477C0B6D]\n",
      "\t(No symbol) [0x00007FF7477B0149]\n",
      "\tBaseThreadInitThunk [0x00007FFDE9767344+20]\n",
      "\tRtlUserThreadStart [0x00007FFDE9AC26B1+33]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#this is for scrape the articles of volumnes and issues.\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import csv\n",
    "import time\n",
    "#intialize the chrome webdriver\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.tandfonline.com/toc/tjis20/33/5?nav=tocList')\n",
    "# Wait for the page to fully load\n",
    "driver.implicitly_wait(20)\n",
    "def getVolumeIssues(url):\n",
    "    driver=webdriver.Chrome()\n",
    "    driver.implicitly_wait(20)\n",
    "    try:\n",
    "        if not url:\n",
    "            return 0\n",
    "        driver.get(url)\n",
    "        # Wait for the page to fully load\n",
    "        driver.implicitly_wait(20)\n",
    "        \n",
    "        \n",
    "        vol_title=driver.find_element(By.CSS_SELECTOR,'div.toc-title')\n",
    "        title=vol_title.text.strip()\n",
    "    \n",
    "       \n",
    "    \n",
    "        articles=driver.find_elements(By.CSS_SELECTOR,'div.art_title')\n",
    "        for article in articles:\n",
    "            try:\n",
    "               # Wait for the element to be present before trying to access it\n",
    "                url_ele = WebDriverWait(article, 10).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, 'a.ref'))\n",
    "                )\n",
    "                # Get the URL\n",
    "                article_url = url_ele.get_attribute('href')\n",
    "                article_title = article.find_element(By.CSS_SELECTOR,'span.hlFld-Title')\n",
    "                title_text = article_title.text.strip()\n",
    "            except Exception as e:\n",
    "                print(\"error at article url\",e)\n",
    "                break\n",
    "            with open('european_journal_of_information_systems.csv', mode='a', newline='', encoding='utf-8') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow([title, article_url, title_text])\n",
    "                    file.flush() \n",
    "    except Exception as e:\n",
    "        print(\"An error occurred while processing volume issues:\", e)\n",
    "    driver.quit()\n",
    "   \n",
    "    \n",
    "def findIssues(url):\n",
    "     #find the issues\n",
    "    driver=webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    print(url)\n",
    "    driver.implicitly_wait(20)\n",
    "    try:\n",
    "        issue_ele = WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, 'div.loi-issues-scroller'))\n",
    "            )\n",
    "        issue_links = issue_ele.find_elements(By.CSS_SELECTOR, 'a')\n",
    "        for issue in issue_links:\n",
    "            href = issue.get_attribute('href')\n",
    "            getVolumeIssues(href)\n",
    "    except Exception as e:\n",
    "        print(f\"Error while finding issues for {url}: {e}\")\n",
    "        getVolumeIssues(url)\n",
    "    driver.quit()\n",
    "urls=['https://www.tandfonline.com/toc/tjis20/3/4?nav=tocList']\n",
    "for i in urls:\n",
    "    findIssues(i)\n",
    "# years_ele=driver.find_element(By.CSS_SELECTOR,'div.yearSliderInner')\n",
    "# years=years_ele.find_elements(By.CSS_SELECTOR,'a.expander')\n",
    "# for year in years:\n",
    "#     url=year.get_attribute('href')\n",
    "#     findIssues(url)\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2a5c05-0b92-46ed-bae8-e3126cf0720e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import csv\n",
    "import time\n",
    "euro_data=pd.read_excel('EJIS1.xlsx')\n",
    "def getAuthorsData(authors):\n",
    "    auth_data=[]\n",
    "    name,url,desc,email='','','',''\n",
    "    for auth in authors:\n",
    "        hover = ActionChains(driver).move_to_element(auth)\n",
    "        hover.perform()\n",
    "        try:\n",
    "            auth_details=auth.find_element(By.CSS_SELECTOR,'a.author')\n",
    "            name=auth_details.text.strip()\n",
    "           \n",
    "            url=auth_details.get_attribute('href')\n",
    "        except Exception as e:\n",
    "            print('error at name and email of author',e)\n",
    "        try:\n",
    "            # Wait for the overlay description to appear\n",
    "            desc = auth.find_element(By.CSS_SELECTOR,'span.overlay').text.strip()\n",
    "        except Exception as e:\n",
    "            print(\"error at description\",e)\n",
    "        try:\n",
    "            email = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, 'span.corr-email a'))\n",
    "            ).text.strip()\n",
    "        except Exception as e:\n",
    "            print(\"error at author email\",e)\n",
    "        auth_data.append([name,url,desc,email])\n",
    "        ActionChains(driver).move_to_element(driver.find_element(By.TAG_NAME, 'body')).perform()\n",
    "    return auth_data\n",
    "        \n",
    "with open('European_journals_articles_data.csv',mode='a',newline='',encoding='utf-8') as file:\n",
    "    writer=csv.writer(file)\n",
    "    writer.writerow(['Journal_Title',\"URL\", \"Article_Title\",'Volume_Issue','Month_Year','Abstract','Keywords','Author_name','Author_url','Author_Address','Author_email'])  # Write the header row\n",
    "for index,row in euro_data.iterrows():\n",
    "    final_data=[]\n",
    "    driver=webdriver.Chrome()\n",
    "    driver.get(row['URL'])\n",
    "    driver.implicitly_wait(10)\n",
    "    try:\n",
    "        #to avoid no such element error use webdriverwait\n",
    "        vol_year_element = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'span.issue-heading'))\n",
    "        )\n",
    "        vol_year = vol_year_element.text.strip()\n",
    "        \n",
    "        vol_issue_element = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'span.issue-heading a'))\n",
    "        )\n",
    "        vol_issue = vol_issue_element.text.strip()\n",
    "    except Exception as e:\n",
    "        print(\"Error occured\",e)\n",
    "    try:\n",
    "        abstract=driver.find_element(By.CSS_SELECTOR,'div.hlFld-Abstract p.last').text.strip()\n",
    "    except Exception as e:\n",
    "        print(\"error at abstraction\",e)\n",
    "    try:\n",
    "        keyword_list_element=driver.find_element(By.CSS_SELECTOR,'div.hlFld-KeywordText')\n",
    "        keyword_list=keyword_list_element.find_elements(By.CSS_SELECTOR,'a.kwd-btn')\n",
    "        keywordlist=[]\n",
    "        for key in keyword_list:\n",
    "            keyword=key.text.strip()\n",
    "            keywordlist.append(keyword)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    final_data=[row['Title'],row['URL'],row['Article_Title'],vol_issue,vol_year,abstract,keywordlist]\n",
    "    try:\n",
    "        authors=driver.find_elements(By.CSS_SELECTOR,'div.addAuthorInfo')\n",
    "        # authors=driver.find_elements(By.CSS_SELECTOR,'div.entryAuthor')\n",
    "        # authdata=getAuthorsData(authors)\n",
    "        for auth in authors:\n",
    "            try:\n",
    "                auth_title=auth.find_element(By.CSS_SELECTOR,'h4').text.strip()\n",
    "            except Exception as e:\n",
    "                auth_title='NA'\n",
    "            try:\n",
    "                auth_email=auth.find_element(By.CSS_SELECTOR,'div.NLM_bio a').text.strip()\n",
    "            except Exception as e:\n",
    "                auth_email='NA'\n",
    "            try:\n",
    "                auth_desc=auth.find_element(By.CSS_SELECTOR,'div.NLM_bio p').text.strip()\n",
    "            except Exception as e:\n",
    "                auth_desc='NA'\n",
    "            with open('European_journals_articles_data.csv', mode='a', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(final_data + [auth_title,auth_desc,auth_email])\n",
    "                file.flush()\n",
    "    except Exception as e:\n",
    "            print(f\"Error processing author data on {row['URL']}: {e}\")\n",
    "    # try:\n",
    "    #     authors=driver.find_elements(By.CSS_SELECTOR,'div.entryAuthor')\n",
    "    #     authdata=getAuthorsData(authors)\n",
    "    #     for i in authdata:\n",
    "    #         with open('european_journals4.csv', mode='a', newline='', encoding='utf-8') as file:\n",
    "    #             writer = csv.writer(file)\n",
    "    #             writer.writerow(final_data + i)\n",
    "    #             file.flush()\n",
    "    # except Exception as e:\n",
    "    #         with open('european_journals4.csv', mode='a', newline='', encoding='utf-8') as file:\n",
    "    #             writer = csv.writer(file)\n",
    "    #             writer.writerow(final_data + [\"N/A\", \"N/A\", \"N/A\"])\n",
    "    #             file.flush()\n",
    "    #         print(f\"Error processing author data on {row['URL']}: {e}\")\n",
    "   \n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fb047f-52c0-4cb5-963f-9bfb4abfc27f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce203fb-0cb2-4115-9a1e-73b3ee0781ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
