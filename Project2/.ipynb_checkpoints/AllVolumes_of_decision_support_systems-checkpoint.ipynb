{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf5cf56-a9a3-4e88-bb5e-bbe6784cb739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import csv\n",
    "#initalize the chrome webdriver\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.sciencedirect.com/journal/decision-support-systems/vol/187/suppl/C')\n",
    "\n",
    "#2024 volumes\n",
    "\n",
    "# Wait for the page to fully load\n",
    "driver.implicitly_wait(20)\n",
    "data=[]\n",
    "def getVolumedata(url):\n",
    "    try:\n",
    "        if not url:\n",
    "            return 0\n",
    "        driver.get(url)\n",
    "        # Wait for the page to fully load\n",
    "        driver.implicitly_wait(20)\n",
    "        articles=driver.find_elements(By.CSS_SELECTOR,'li.js-article-list-item dl.js-article')\n",
    "        vol_issue=driver.find_element(By.CLASS_NAME,'js-vol-issue').text.strip()\n",
    "        vol_iss_year=driver.find_element(By.CLASS_NAME,'js-issue-status').text.split('(')[-1].strip(') ')\n",
    "        \n",
    "        for article in articles:\n",
    "            article_url_element=article.find_element(By.CSS_SELECTOR,'a.article-content-title')\n",
    "            article_url=article_url_element.get_attribute('href')\n",
    "            article_title=article.find_element(By.CLASS_NAME,'js-article-title').text.strip()\n",
    "            \n",
    "            data.append([article_title,article_url,vol_issue,vol_iss_year])\n",
    "        prev_ele=driver.find_element(By.CSS_SELECTOR,'nav.issue-navigation div.navigation-pre a.text-m')\n",
    "        prev_ele_url=prev_ele.get_attribute('href')\n",
    "        with open('decision_support_systems.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Title\", \"URL\",\"Volume Issue\",\"Vol Issue Year\"])  # Write the header row\n",
    "            writer.writerows(data)  # Write the article title and URL data rows\n",
    "        return getVolumedata(prev_ele_url)\n",
    "    except Exception as e:\n",
    "        print(\"Exception\",e)\n",
    "       \n",
    "try:\n",
    "    articles=driver.find_elements(By.CSS_SELECTOR,'li.js-article-list-item dl.js-article')\n",
    "    vol_issue=driver.find_element(By.CLASS_NAME,'js-vol-issue').text.strip()\n",
    "    vol_iss_year=driver.find_element(By.CLASS_NAME,'js-issue-status').text.split('(')[-1].strip(') ')\n",
    "    for article in articles:\n",
    "        article_url_element=article.find_element(By.CSS_SELECTOR,'a.article-content-title')\n",
    "        article_url=article_url_element.get_attribute('href')\n",
    "        article_title=article.find_element(By.CLASS_NAME,'js-article-title').text.strip()\n",
    "        \n",
    "        \n",
    "        data.append([article_title,article_url,vol_issue,vol_iss_year])\n",
    "    prev_ele=driver.find_element(By.CSS_SELECTOR,'nav.issue-navigation div.navigation-pre a.text-m')\n",
    "    prev_ele_url=prev_ele.get_attribute('href')\n",
    "    with open('decision_support_systems.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Title\", \"URL\",'Volume Issue','Month Year'])  # Write the header row\n",
    "        writer.writerows(data)  # Write the article title and URL data rows\n",
    "    getVolumedata(prev_ele_url)\n",
    "except Exception as e:\n",
    "    print(\"Exception\",e)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba9be61-63ad-4183-a416-fe3fe29ac7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import csv\n",
    "import time\n",
    "\n",
    "#initalize the chrome webdriver\n",
    "driver=webdriver.Chrome()\n",
    "journals_data=pd.read_csv('decision_support_systems.csv')\n",
    "journal_urls=journals_data['URL']\n",
    "\n",
    "# driver.get('https://www.sciencedirect.com/science/article/pii/0167923685901915')\n",
    "# # Wait for the page to fully load\n",
    "# driver.implicitly_wait(20)\n",
    "# author_group=driver.find_elements(By.CSS_SELECTOR,'div.author-group')\n",
    "# if author_group:\n",
    "#     print('author group')\n",
    "# else:\n",
    "#     print('no author group')\n",
    "def getAuthorsData(authors):\n",
    "    authdata=[]\n",
    "    for auth in authors:\n",
    "        auth.click()\n",
    "        # Wait for the side panel to open\n",
    "        time.sleep(2)  \n",
    "        auth_data=driver.find_element(By.CSS_SELECTOR,'div.side-panel-content')\n",
    "        auth_data_desc=auth_data.find_element(By.CSS_SELECTOR,'div.affiliation')\n",
    "        auth_name=auth_data.find_element(By.CSS_SELECTOR,'div.author')\n",
    "        name=auth_name.text.strip()\n",
    "        desc=auth_data_desc.text.strip()\n",
    "        try:\n",
    "            auth_email=auth_data.find_element(By.CSS_SELECTOR,'div.e-address a.anchor')\n",
    "            email=auth_email.text.strip()\n",
    "        except Exception as e:\n",
    "            email='N/A'\n",
    "        authdata\n",
    "        authdata.append([name,email,desc])\n",
    "    return authdata\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "whole_data=[]\n",
    "for url in journal_urls:\n",
    "    try:    \n",
    "        final_data=[]\n",
    "        driver.get(url)\n",
    "        # Wait for the page to fully load\n",
    "        driver.implicitly_wait(20)\n",
    "        # Wait for the page to load using WebDriverWait\n",
    "        try:\n",
    "            WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, 'h1.Head'))\n",
    "            )\n",
    "            title=driver.find_element(By.CSS_SELECTOR,'h1.Head').text.strip()\n",
    "            article_details=driver.find_element(By.CSS_SELECTOR,'div.Publication')\n",
    "            article_journal=article_details.find_element(By.CSS_SELECTOR,'h2.publication-title').text.strip()\n",
    "            article_vol=article_details.find_element(By.CSS_SELECTOR,'div.text-xs a.anchor').text.strip()\n",
    "                    \n",
    "            article_month_year=article_details.find_element(By.CSS_SELECTOR,'div.text-xs').text.split(',')[1]\n",
    "            \n",
    "        except TimeoutException:\n",
    "            print(f\"Timeout: Page did not load properly for {url}\")\n",
    "            continue\n",
    "        try:\n",
    "            author_group=driver.find_element(By.CSS_SELECTOR,'div.author-group')\n",
    "            final_data=[url,article_journal,title,article_vol,article_month_year]\n",
    "            if author_group:\n",
    "                authors=author_group.find_elements(By.CSS_SELECTOR,'button.button-link')\n",
    "                auth_data=getAuthorsData(authors)\n",
    "                for i in auth_data:\n",
    "                    whole_data.append(final_data+i)\n",
    "            else:\n",
    "                whole_data.append(final_data)\n",
    "        except Exception as e:\n",
    "            print(\"error in finding the authors\")\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(\"Page not loading\",e)\n",
    "with open('decision_support_systems_journal.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['URL',\"Journal_Title\", \"Article_Title\",'Volume_Issue','Month_Year','Author_name','Author_email','Author_Address'])  # Write the header row\n",
    "    writer.writerows(whole_data)  # Write the article title and URL data rows\n",
    "\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
