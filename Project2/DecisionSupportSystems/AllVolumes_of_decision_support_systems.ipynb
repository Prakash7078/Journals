{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf5cf56-a9a3-4e88-bb5e-bbe6784cb739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information systems and decision support systems and Journal of strategic information systems have same journal UI so I am using this code for both of them.\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import csv\n",
    "#initalize the chrome webdriver\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.sciencedirect.com/journal/the-journal-of-strategic-information-systems/vol/34/issue/2')\n",
    "\n",
    "\n",
    "# Wait for the page to fully load\n",
    "driver.implicitly_wait(20)\n",
    "data=[]\n",
    "def getVolumedata(url):\n",
    "    try:\n",
    "        if not url:\n",
    "            return 0\n",
    "        driver.get(url)\n",
    "        # Wait for the page to fully load\n",
    "        driver.implicitly_wait(20)\n",
    "        articles=driver.find_elements(By.CSS_SELECTOR,'li.js-article-list-item dl.js-article')\n",
    "        vol_issue=driver.find_element(By.CLASS_NAME,'js-vol-issue').text.strip()\n",
    "        vol_iss_year=driver.find_element(By.CLASS_NAME,'js-issue-status').text.split('(')[-1].strip(') ')\n",
    "        \n",
    "        for article in articles:\n",
    "            article_url_element=article.find_element(By.CSS_SELECTOR,'a.article-content-title')\n",
    "            article_url=article_url_element.get_attribute('href')\n",
    "            article_title=article.find_element(By.CLASS_NAME,'js-article-title').text.strip()\n",
    "            \n",
    "            data.append([article_title,article_url,vol_issue,vol_iss_year])\n",
    "        prev_ele=driver.find_element(By.CSS_SELECTOR,'nav.issue-navigation div.navigation-pre a.text-m')\n",
    "        prev_ele_url=prev_ele.get_attribute('href')\n",
    "        with open('Journal_of_SIS.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Title\", \"URL\",\"Volume Issue\",\"Vol Issue Year\"])  # Write the header row\n",
    "            writer.writerows(data)  # Write the article title and URL data rows\n",
    "        return getVolumedata(prev_ele_url)\n",
    "    except Exception as e:\n",
    "        print(\"Exception\",e)\n",
    "       \n",
    "try:\n",
    "    articles=driver.find_elements(By.CSS_SELECTOR,'li.js-article-list-item dl.js-article')\n",
    "    vol_issue=driver.find_element(By.CLASS_NAME,'js-vol-issue').text.strip()\n",
    "    vol_iss_year=driver.find_element(By.CLASS_NAME,'js-issue-status').text.split('(')[-1].strip(') ')\n",
    "    for article in articles:\n",
    "        article_url_element=article.find_element(By.CSS_SELECTOR,'a.article-content-title')\n",
    "        article_url=article_url_element.get_attribute('href')\n",
    "        article_title=article.find_element(By.CLASS_NAME,'js-article-title').text.strip()\n",
    "        \n",
    "        \n",
    "        data.append([article_title,article_url,vol_issue,vol_iss_year])\n",
    "    prev_ele=driver.find_element(By.CSS_SELECTOR,'nav.issue-navigation div.navigation-pre a.text-m')\n",
    "    prev_ele_url=prev_ele.get_attribute('href')\n",
    "    with open('Journal_of_SIS.csv', mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Title\", \"URL\",'Volume Issue','Month Year'])  # Write the header row\n",
    "        writer.writerows(data)  # Write the article title and URL data rows\n",
    "    getVolumedata(prev_ele_url)\n",
    "except Exception as e:\n",
    "    print(\"Exception\",e)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78553a0b-8fef-4c5d-8bc0-af7184fe4ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error at abstraction Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"div.sp0050\"]\"}\n",
      "  (Session info: chrome=132.0.6834.160); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF75E1D02F5+28725]\n",
      "\t(No symbol) [0x00007FF75E132AE0]\n",
      "\t(No symbol) [0x00007FF75DFC510A]\n",
      "\t(No symbol) [0x00007FF75E0193D2]\n",
      "\t(No symbol) [0x00007FF75E0195FC]\n",
      "\t(No symbol) [0x00007FF75E063407]\n",
      "\t(No symbol) [0x00007FF75E03FFEF]\n",
      "\t(No symbol) [0x00007FF75E060181]\n",
      "\t(No symbol) [0x00007FF75E03FD53]\n",
      "\t(No symbol) [0x00007FF75E00A0E3]\n",
      "\t(No symbol) [0x00007FF75E00B471]\n",
      "\tGetHandleVerifier [0x00007FF75E4FF30D+3366989]\n",
      "\tGetHandleVerifier [0x00007FF75E5112F0+3440688]\n",
      "\tGetHandleVerifier [0x00007FF75E5078FD+3401277]\n",
      "\tGetHandleVerifier [0x00007FF75E29AAAB+858091]\n",
      "\t(No symbol) [0x00007FF75E13E74F]\n",
      "\t(No symbol) [0x00007FF75E13A304]\n",
      "\t(No symbol) [0x00007FF75E13A49D]\n",
      "\t(No symbol) [0x00007FF75E128B69]\n",
      "\tBaseThreadInitThunk [0x00007FFFF94E7344+20]\n",
      "\tRtlUserThreadStart [0x00007FFFF97826B1+33]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import csv\n",
    "import time\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "\n",
    "#initalize the chrome webdriver\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "# journals_data=pd.read_csv('Journal_of_SIS.csv')\n",
    "journals_data=pd.read_csv('decision_support_systems.csv')\n",
    "# journal_urls=journals_data['URL']\n",
    "# driver.get('https://www.sciencedirect.com/science/article/pii/0167923685901915')\n",
    "# # Wait for the page to fully load\n",
    "# driver.implicitly_wait(20)\n",
    "# author_group=driver.find_elements(By.CSS_SELECTOR,'div.author-group')\n",
    "# if author_group:\n",
    "#     print('author group')\n",
    "# else:\n",
    "#     print('no author group')\n",
    "def getAuthorsData(authors,driver):\n",
    "    authdata=[]\n",
    "    for auth in authors:\n",
    "        name,desc='',''\n",
    "        try:\n",
    "            auth.click()\n",
    "            # Wait for the side panel to open\n",
    "            time.sleep(2)  \n",
    "            auth_data=driver.find_element(By.CSS_SELECTOR,'div.side-panel-content')\n",
    "            auth_data_desc=auth_data.find_element(By.CSS_SELECTOR,'div.affiliation')\n",
    "            auth_name=auth_data.find_element(By.CSS_SELECTOR,'div.author')\n",
    "            name=auth_name.text.strip()\n",
    "            desc=auth_data_desc.text.strip()\n",
    "        except Exception as e:\n",
    "            print(\"error at author data\",e)\n",
    "        try:\n",
    "            auth_email=auth_data.find_element(By.CSS_SELECTOR,'div.e-address a.anchor')\n",
    "            email=auth_email.text.strip()\n",
    "        except Exception as e:\n",
    "            email=None\n",
    "        authdata\n",
    "        authdata.append([name,email,desc])\n",
    "    return authdata\n",
    "        \n",
    "\n",
    "\n",
    "with open('dss_articles.csv', mode='a', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['URL','Journal_Title','Article_Title','Volume_Issue','Month_Year','Abstract','Keywords','Author_name','Author_email','Author_Address'])\n",
    "    \n",
    "\n",
    "\n",
    "for index,row in journals_data[:2].iterrows():\n",
    "    # service = Service(r\"C:\\Users\\H664K297\\Documents\\Journals\\Project2\\chromedriver-win64\\chromedriver.exe\")\n",
    "    driver = webdriver.Chrome()\n",
    "    final_data=[]\n",
    "    url=row['URL']\n",
    "    article_date=row['Vol Issue Year']\n",
    "    driver.get(url)\n",
    "    # Wait for the page to fully load\n",
    "    driver.implicitly_wait(10)\n",
    "    # Wait for the page to load using WebDriverWait\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'h1.Head'))\n",
    "        )\n",
    "        title=driver.find_element(By.CSS_SELECTOR,'h1.Head').text.strip()\n",
    "        article_details=driver.find_element(By.CSS_SELECTOR,'div.Publication')\n",
    "        article_journal=article_details.find_element(By.CSS_SELECTOR,'h2.publication-title').text.strip()\n",
    "        article_vol=article_details.find_element(By.CSS_SELECTOR,'div.text-xs a.anchor').text.strip()\n",
    "                \n",
    "        # article_month_year=article_details.find_element(By.CSS_SELECTOR,'div.text-xs').text.split(',')[1]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error is {e} in this {url}\")\n",
    "    try:\n",
    "        abstract=driver.find_element(By.ID,'div.sp0050').text.strip()\n",
    "    except Exception as e:\n",
    "        abstract=None\n",
    "        print(\"error at abstraction\",e)\n",
    "    try:\n",
    "        keywords=driver.find_elements(By.CSS_SELECTOR,'div.keyword')\n",
    "        keyword_list=[]\n",
    "        for key in keywords:\n",
    "            keyword=key.text.strip()\n",
    "            keyword_list.append(keyword)\n",
    "    except Exception as e:\n",
    "        print('error at keywords',e)\n",
    "\n",
    "        \n",
    "    final_data=[url,article_journal,title,article_vol,article_date]\n",
    "    final_data.append(abstract)\n",
    "    final_data.append(keyword_list)\n",
    "    try:\n",
    "        author_group=driver.find_element(By.CSS_SELECTOR,'div.author-group')\n",
    "        authors=author_group.find_elements(By.CSS_SELECTOR,'button.button-link')\n",
    "        auth_data=getAuthorsData(authors,driver)\n",
    "        for i in auth_data:\n",
    "            with open('dss_articles.csv', mode='a', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(final_data + i)\n",
    "                file.flush()\n",
    "    except Exception as e:\n",
    "            with open('dss_articles.csv', mode='a', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(final_data + [\"N/A\", \"N/A\", \"N/A\"])\n",
    "                file.flush()\n",
    "            print(f\"Error processing author data on {url}: {e}\")\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2fbdb9-372d-4f46-b41b-45cd04aa007e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
